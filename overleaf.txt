\chapter{State of The Art}

\section{Pipeline}
A pipeline can be defined as a series of consecutive events, that are automated and where the output of one event is the input of the next one.

\subsection{CI/CD}
CI/CD means Continuous Integration/Continuous Development, we will start by explaining the concept of Continuous Integration.
Usually a pipeline start with the CI this means that when new code is added to a repository a series of events will be trigger in order to check if the new code integrates with the application. A few examples of this is running automatic code scans to check if the code was programmed according to good coding practices, the process of building the code and running the unit tests also takes part within the Continuous Integration part. When we are sure that the new code has the quality we require and doesn't break any old functionality that we used to have, we can deploy the application automatically and this is called Continuous Delivery.

\section{Kernel}
The kernel is the heart of a computer's operating system, when a computer is booted up and the bootloader has finished then it's up to the kernel to handle the rest of the start-up. It provides a commutation between the user interface, the CPU, memory and any other I/O device.

\section{Syscalls}
Syscalls are what a process uses to talk to the kernel, they usually occur when a process needs to access a certain resource and ask the kernel for permission via syscalls.

\section{Least Privilege Principle}
This principle states that in a computer system we should give the minimum required privileges in order for the system to work correctly. This means that the software should only be capable of doing or accessing only the information that it needs. By working with this principle we are shrinking the attacks vector that an attacker has to work with.

\section{Containers}
A different approach using virtualization technology since it differs from the traditional hypervisor based virtual machines. Containers are lightweight applications that allow us to package both the code and all of the dependencies in order for that application to be executed. A container shares the hosts kernel and run as a resource-isolated processes which means he have stable deployments despite of the environment configuration. This also makes containers superior when it comes to distributing the application.
\medskip \\ 

\subsection{Kernel Namespaces}
Kernel Namespaces provide a layer of isolation between each container, meaning that a given process within a container cannot see a process from another container or the host system, in other words the container will run in that separate namespace and all it has access is limited to that specific namespace.


\subsection{Control Groups}
Control Groups are a Linux kernel feature that is responsible for the container resource allocation, it will limit the CPU usage, memory, disk I/O between containers which allows hardware to be shared and optionally enforce limits and constraints between containers. It plays a significant part when dealing with a Denial-of-service attack since it will limit the compromised container resources so the system can keep running smoothly.

\subsection{Containerd}
Default runtime used by the Docker engine, which is responsible for managing the container life cycle from the moment the image is transferred until it is destroyed. It also makes sure the container is being executed calling RunC. It provides a higher level of abstraction that manages syscalls and OS specific functionalities.

\subsection{RunC}
The standard low level container runtime which provides a command line interface. RunC is usually used by a higher level container runtime and is responsible for spawning and running containers. Although it can be used as a stand-alone tool. RunC is responsible for creating the custom namespaces for a specific container, setting the control groups parameters and mounting the container file system.

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/StateArt/dockerArch.png}
  \captionof{figure}{\label{fig:DockerArch}Docker Flow.}
\end{minipage}
\end{figure}


\subsection{Docker}
A tool that allows to create and manage a containerize application, at the moment is the industry standard.

\subsubsection{Docker Image}
A file used to execute an application in a Docker Container, from the moment an image runs it becomes an instance of that Container.

\subsubsection{Docker Client}
Component responsible for providing a command line interface that allows us to communicate with the Docker Daemon.

\subsubsection{Docker Daemon}
Component responsible for provisioning a container. The Docker Client will send a command to the Docker Daemon, the Daemon will evaluate and respond to the request. The Daemon must run with root privileges, before we start deploying containers we need to make sure that only trusted users have access to the Docker Daemon, since an untrusted user with access to the Daemon can create containers as he pleases. 

\subsubsection{Docker Content Trust Signature Verification}
Responsible for ensuring that we only pull or run images from a signed repository in order not to run an image from an untrustworthy source.

\subsection{Privileged Container}
Privileged containers are used in a debug environment and should never be deployed in production. Some of the features that are used to isolate containers are not used when deploying a privileged container, the most significant are full capabilities and lifts the limitations enforced by cgroups. If an attacker gains access to a privileged container they are basically root on the host.

	

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/StateArt/docker.png}
   \captionof{figure}{\label{fig:DockerArch}Docker Architecture.}
\end{minipage}
\end{figure}

\subsection{Kata Containers}
Kata Containers provide a more secure container runtime alternative to RunC hence it builds a fast, lightweight virtual machine around the container this provides a stronger isolation than a stand-alone container. It is capable of achieving this with the help of Intel Clear Containers that provide a hardware virtualization solution as another isolation technique. Since each container has its own virtual machine the kernel is not being shared with the host system or any other container running in the same machine. The benefit to this is that any type of malicious code can no longer exploit the shared kernel therefore reducing the attack vectors.
The drawback is the overhead created by having a container inside a virtual machine, we found that tasks that need significant memory access are much slower. 

\begin{figure}
\centering
\begin{minipage}{.5\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/StateArt/kata.png}
  \captionof{figure}{\label{fig:DockerArch}Kata Containers Architecture.}
\end{minipage}
t\end{figure}


\subsection{gVisor}
Google's container runtime, where the objective is to create a sandbox around each container providing strong isolation and not being as resource hungry as a VM. The runtime is called Runsc, which runs containers in a separate user-space kernel. When talking about virtualization technologies, there are usually two spaces, the kernel space and the user space. In the kernel space only privilege tasks are allowed to execute such as kernel extensions and the operating system kernel. On the other hand the user space if for application software. Not only it runs the container on a separate user-space kernel, but also limits the syscalls that the container can make to the host kernel.

\subsection{Userns-remap}
Userns-remap is a must do when we need to run a given application as root inside the container. If we don't the possibility of a privilege escalation is much higher since if there is a container escape vulnerability than the attacker can gain root privileges on the host. To prevent this, we can map the root user inside the container to an unprivileged user outside of the container. Some OS like RHEL and CentOS 7.3 need to be manually updated to add a new group in the /etc/subuid and /etc/subgid files.

\subsection{Rootless mode}
A solution where the Docker Daemon does not need to run as root, very helpful when we need to mitigate potential attack vectors (Docker Daemon). There are some known limitation when working with this mode such as : 
\begin{itemize}
    \item AppArmor is not supported
    \item Exposing SCTP ports
    \item Exposing privileged TCP/UDP ports
    \item Cgroups
\end{itemize}

\subsection{Secure Computing Mode}
Secure Computing Mode also known as seccomp, is a Linux kernel feature that sends a process into a secure state where it has a whitelist of syscalls that the process can perform. 


\subsection{CoreOS rkt}
Docker alternative, it was developed with some security features in mind. Whenever an image is pulled, it will check the image signature to ensure integrity also makes use of Intel Clear Containers that allows CPU-Enforced Isolation this gives us an extra layer of security between containers. However rkt hasn't been updated in quite some time and by now Docker has caught up with those rkt features.

\section{Orchestration}
Automatic process of managing, coordinating and deploying several containers in order to reliably execute the workflow of a given application. This usually happens over multiple hosts in multiple cloud environments, there are some key features that an orchestrator should have such as scalability, service discovery, orchestration of the containers, node communication between other for some more specific cases.
\medskip \\ 

\subsection{Kubernetes}
Container orchestration tool capable of creating application deployments, scale up or down the worker nodes. Currently is the standard in container orchestration which comes with a benefit of having a huge community that keeps creating new tools to integrate with Kubernetes.

\begin{figure}
\centering
\begin{minipage}{1\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/StateArt/kubernetes.png}
  \captionof{figure}{\label{fig:KubeArch}Kubernetes Architecture.}
\end{minipage}
\end{figure}

\subsubsection{Pod}
A Pod consists of one or more containers which are relatively dependent on each other, the containers will run in a shared context meaning a shared file system and network.

\subsubsection{Kubelet}
Kubelet runs on every node of the cluster, it takes a PodSpec, which is a YAML file describing what will be deployed, and ensures that the containers that are supposed to run on that node are running and are healthy.

\subsubsection{Kube Proxy}
Network proxy that runs on every node of the cluster to achieve service discovery, this is the act of discovering new services within the application. In a Kubernetes environment, it is extremely important since at any given time there are new services in the network.

\subsubsection{Etcd}
Distributed key-value store for critical data on a distributed system, in a Kubernetes cluster we see that the etcd stores a variety of information about the cluster like configuration data, cluster state, and its metadata. 

\subsubsection{Rancher}
Tool to easily deploy and manage a Kubernetes cluster, it has set of tools built-in to facilitate the orchestration process. We are presented with a Web UI capable of managing out infrastructure in multiple environments.

\subsubsection{Helm}
A package manager for Kubernetes, we can easily deploy any given application that has the deployment files (Charts) in the Helm repository. Helm provides us with two different components, firstly, the command-line client for end users where we can search for Charts, and deploy them, secondly, Tiller which is the Helm server-side that run on every node of the cluster and is responsible for processing a chart and generating the Kubernetes resource manifests.

\begin{figure}
\centering
\begin{minipage}{.45\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/StateArt/helm.png}
  \captionof{figure}{\label{fig:HelmArch}Helm Architecture.}
\end{minipage}
\end{figure}

\subsection{Docker Swarm}
Dockers container orchestration tool where they have defined the mode “swarm” meaning that the Docker Engine works with other instances of the Docker Engine. It has some security features out of the box like the usage of TLS between nodes, this happens because the master node generates a new Certificate Authority, a worker token and a manager token. When a new worker joins the cluster both the CA and the token are used to set up a secure communication.  

\begin{figure}
\centering
\begin{minipage}{1\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/StateArt/swarm.png}
  \captionof{figure}{\label{fig:SwarmArch}Docker Swarm Architecture.}
\end{minipage}
\end{figure}


\subsection{Nomad}
HashiCorp's take on an orchestration tool. Allows the deployment of both containerized application and non-containerized applications. Nomad has a smaller scope than Kubernetes since its core functionalities are cluster management and scheduling. In order to have a fully working cluster one must integrate Nomad with Consul since Nomad by itself does not support service discovery. 

\subsection{OpenShift}
Orchestration tool developed by Red Hat, is a subscription base service slightly more limited since you can only run OpenShift in a Red Hat OS. Also has some strict security policies like being unable to run a container as root.

\begin{center}
\begin{tabular}{ |c|c|c|c|c| }
 \hline
  & Kubernetes &Swarm & Nomad & OpenShift\\
 \hline
 OpenSource & \CIRCLE & \CIRCLE & \RIGHTcircle & \CIRCLE \\
 Free & \CIRCLE & \CIRCLE & \RIGHTcircle & \RIGHTcircle \\
 Compatibility & \CIRCLE & \CIRCLE& \CIRCLE & \Circle \\
 Service Discovery & \CIRCLE & \CIRCLE & \Circle & \CIRCLE\\
 Simplicity &  \Circle & \RIGHTcircle & \CIRCLE & \RIGHTcircle \\
 Scalability & \CIRCLE & \RIGHTcircle & \CIRCLE & \RIGHTcircle\\
 \hline
\end{tabular}\par
\bigskip
\CIRCLE = Yes\\
\Circle = No\\
\RIGHTcircle = Roughly\\
\end{center}



\section{Monitorization}
After deploying our application in the cluster we may wish to keep tabs on it, to make sure everything is running smoothly. We can achieve this by seeing the logs of the pod, there are some useful monitoring tools that will centralize all of the logs so we can easily check every pod in our cluster.


\subsection{The Efk Stack}
A collection of three open-source projects, Elasticsearch, Fluentd, and Kibana, with them, we can gather different types of information about our cluster and the running application. Each of these projects have their place within the cluster, Fluentd is running in each pod and is responsible for gathering all of the logs which will be forwarded to Elasticsearch and here we will be able to search through the logs and it will provide us several analytics. Finally Kibana presents us with a Web UI where we can easily visualize the logs information, but also create different types of charts.


\begin{figure}
\centering
\begin{minipage}{1\textwidth}
  \centering
  \includegraphics[width=1\linewidth]{Figures/StateArt/elk.png}
  \captionof{figure}{\label{fig:EfkArch}Efk Stack Architecture.}
\end{minipage}
\end{figure}

\subsection{Prometheus}
An open-source monitoring systems that integrate with Grafana to display the collected data. Prometheus heart is the Prometheus Server, which is responsible for collecting metrics from each node periodically and stores them locally, this is possible since each node exposes and endpoint which the Prometheus server will scrape and gather the metrics. In case the node doesn't expose the endpoint there is an alternative, the Push gateway, we rely on the gateway API which will capture the data, transform that data into the Prometheus data format and then push that data into the Prometheus server. Prometheus does not support TLS between the server and the node endpoint but we can achieve this by having a reverse proxy set up.

\subsection{Splunk}
A tool used mainly for monitoring with some other functionalities like searching, analyzing, and visualizing the cluster generated data in real time. One of the main advantages is the fact that we don't need to use a database to store the log data since Splunk makes use of its indexes to store the data. There are three main components of Splunk, the Forwarder is responsible for collecting data in every node of the cluster and forward it to the Indexer which will then be processed and stored with indexation. Finally, we have the Search Head this is where the users interact, search and analyse the logs.


\subsection{Stackdriver}
A service offered by Google that integrates very well when deploying a cluster in the Google Kubernetes Engine (also possible when using AWS). Stackdriver gives us the possibility to monitor, collects metrics, metadata, performs health checks and generate dashboards, charts, and alerts. It offers a really simple and effective way of searching through the logs and finding exactly what you want. A great feature of this tool is that we can see the information of several clusters all from the same web UI and since it provides a multi-cloud environment we can see clusters running in different cloud operator and correlate their information. Stackdriver makes use of two already known technologies, Prometheus collects its metrics and Fluentd for logging purposes. 

\subsection{Inspect}%docker run -d -v /Users/nunolopes/Desktop/Kubernetes/sysdig:/captures -p8080:3000 sysdig/sysdig-inspect:latest
Inspect is an open source tool from Sysdig which aims to report on container issues, low level system error, compare container activities and correlate events between them. Also provides several logs on processes, system calls, threads, port bindings, page faults. A must have tool when it comes to low level monitoring. 



\section{Security}
In this section we will discuss several technologies that allow for a safer orchestration pipeline. We start by explaining some of the built in features that Kubernetes has. Afterwards we describe some technologies that can be attached to our pipeline. We will focus on solutions that provide us with:
\begin{itemize}
    \item Runtime Security
    \item Network Security
    \item Image Scanning
    \item Secrets Management
\end{itemize}


\subsection{Kubernetes Features}

\subsubsection{Role-based access control}
With this feature we are able to control which user has access to other Kubernetes services or any given action within the Pod. We can easily define this using Kubernetes ClusterRole.

\subsubsection{Pod Policies}
We can use Pod policies to control the Pod actions. Giving us a good understanding of what a certain Pod is allowed to do. With this we can define whether a Pod is running as root or not, which takes a good part when it comes to best practices.

\subsubsection{Network Policies}
Network Policies allow us to control the cluster traffic, between pods. Meaning we can define exactly what Pods can communicate with each other. Having a good understanding of how the traffic flows and restricting it when necessary is a must when it comes to reducing the network security risks.

\subsubsection{Secrets Management}
Secret is a Kubernetes object that is used to store sensitive data. Being able to store this information in a Secret allows for more control over who has access to a given secret. To use this feature we first create a new Secret using the kubectl CLI, afterwards we modify our Pod definition and add a new volume containing our secret. 

\subsubsection{Instance-per-Pod}
Kubernetes solution to mitigate kernel, CPU vulnerabilities that would trigger a container breakout granting access to all other Pods running on that same node. Instance-per-Pod creates a specific configuration in order to avoid having multiple pods in the same node.

\subsection{Companies}
Here we will introduce several companies that have some interesting security solutions. Some offer a variety of open source tools while others have a close source or commercial license base. 
\medskip \\ 

\subsubsection{Aquasecurity}
A company that offers solutions to improve the security in a CI/CD pipeline, they have several interesting open source projects directed to a Kubernetes cluster. We have a variety of different tools that help with image scanning and compliance checks.

\subsubsection{Sysdig}
A company that focuses on container security they provide an effective way to deliver reliable, secure applications. Firstly, they scan container images in search of vulnerabilities and enforce security best practices on them, secondly, they provide a runtime security tool capable of knowing when a certain action is performed and monitoring the whole system making use of Prometheus. Lastly performs incident alerts and audit the system. Sysdig works on a subscription base system, but has two great open source tools. 
\subsubsection{Neuvector}
Company providing solutions to reinforce the Kubernetes security, it supports container image scanning that integrates with the CI/CD pipeline, runtime Security that detects and blocks suspicious process or syscall between other possibilities and also a container firewall that detects attacks like DDoS, DNS, SQL Injection. Neuvector tool works well with Kubernetes, Openshift, IBM Cloud, Google Cloud and AWS. 

\subsubsection{HashiCorp}
A company that provides several tools with a focus on infrastructure. Not all of their solutions target the improvement of the security in a Kubernetes cluster.

\subsubsection{Aporeto}
A company that enforces a Zero Trust Cloud Security architecture in their products. Zero Trust Cloud Security works by first, defining the protect surface where the most important services will be on. Secondly, we must understand how the traffic flow from an to our previously defined protects surface, this means what applications and users access the information stored in the protect surface. Once we have a good understanding we must define the correct policies in order to restrict the access.

\subsubsection{Tigera}
A company that focuses on delivering firewall solutions to a Kubernetes cluster using Zero-Trust Network, it works on a commercial license base.


\subsection{Runtime Security}
An ongoing process that detects and blocks certain actions within the running Pod.
\medskip \\ 

\subsubsection{SELinux}
Security-Enhanced Linux is an implementation which aims to enhance the systems security and in case of a security breach it also stops the breach from spreading to the entire system. With SELinux we have control over what services have access to, when properly implemented, we can neutralize a lot of attacks. Besides, it is good practice to only allow a service to fetch the needed files.


\subsubsection{AppArmor}
AppArmor is similar to SELinux, it is a lot easier to define rules, but it isn't as flexible as SELinux. With AppArmor it is possible to easily define what a given service is allowed or not to do according to the principle of least privilege.

\subsubsection{Seccomp}
Seccomp or Secure Computing Mode is a tool that enables a give process to transit into a secure state. In this secure state the process is only allowed to perform certain syscalls to only open file descriptors. If by any change there it performs a syscall that is not allowed the process will be terminated.


\subsubsection{Falco}
Open source tool from Sysdig, capable of alerting when something suspicious is happening within the containers. We can define what type of activities are considered suspicious and Falco will alert accordingly. Some examples are alerting when a shell is spawned, a container running in privileged mode, reading a sensitive file and many others.

\subsection{Network Security}
Network Security is the action of protecting our system against any type of attack or misuse that utilizes the network vector.
\medskip \\ 

\subsubsection{Aporeto}
Tool from Aporeto (company) that works on a commercial license based. We are able to create a Zero Trust Cloud Security architecture with this tool. Define the protect surface, create policies to whom has access to it, define firewalls within the protected surface perimeter and enforcing a least privilege access policy when an access to the protected surface occurs.


\subsubsection{Calico}
Open source project managed by the Tiger a Team, Tigera offers a subscription license where they help with the deployment of Calico and any support needed. Calico can be used in a multi cloud environment, from Google Cloud to Aws and can be integrated with Kubernetes, Docker, Open Shift. With Calico we can define network policies to only allow traffic in and out from the supposed services, it does this dynamically since in a cluster at any given moment there are new services being deployed or being scaled. 

\subsubsection{Cilium}
Open source project working on a multi cloud environment from Google Cloud to Amazon AWS. Cilium makes use of BPF (Berkeley Packet Filter) which enables us to analyze network traffic and filter any unwanted traffic. Cilium makes use of this feature by only allowing the type of traffic wanted into our network and as usual we can define which Pods can talk to each other. Using Cilium we can easily define policies about which services can access what API endpoints having this kind of control allows for a least privileged implementation. 

\subsubsection{Istio}
Open source project that integrates with several other network tools, when deploying a cluster on Google Cloud we can set up Istio by a simple click of a button. Istio takes care of several components from visibility, security and policy enforcement. We can create several graphs to identify any given problem with a network based giving us a good visibility on how our cluster communicates. Istio also allows us to easily set up load balancing policies defining exactly what percentage of the traffic goes what Pod. It also provides service discovery since Istio will deploy a helper proxy container throughout the environment. Once the proxy is installed all communication will be performed via this proxy.


\subsection{Image Scanning}
Image scanning refers to the action of going through an images listing the component  versions and checking whether there are any known vulnerabilities for that running version. 
\medskip \\ 

\subsubsection{Anchore}
Anchore provides both an open source version and a commercial one for image scanning. Providing inspection and analysis of an image, everything from third-party libraries to the packages used in the image. 

\subsubsection{Clair}
Open source tool for static analysis of container images. At regular intervals Clair will scan the docker images and check if there any known vulnerabilities in the versions specified. If a vulnerability is found Clair can send an alert to an event management system.

\subsubsection{Snyk}
Snyk is very similar to Clair, since it scans a container image for vulnerabilities, it also offers some new functionalities like auto-upgrading to the most recent image and a very good vulnerability database. Unlike Clair, Snyk works on a subscription base system.

\subsubsection{Trivy}
Open source tool from Aquasecurity, responsible for scanning container images for vulnerabilities and known issues. Trivy can be very helpful when working with the base images from Alpine or RHEL/CentOS and it integrates in a CI environment working tools like Jenkins and Tavis.

\subsubsection{Docker Trusted Registry}
Docker offers a Registry in order for an organization to have a secure way to store their images. It comes with some additional features as image scanning.

\begin{center}
\begin{tabular}{ |c|c|c|c|c|c| }
 \hline
  & Anchore & Clair & Snyk & Trivy & DTR\\
 \hline
 OpenSource & \CIRCLE & \CIRCLE & \CIRCLE & \CIRCLE & \Circle \\
 Free & \CIRCLE & \CIRCLE & \Circle & \CIRCLE & \Circle \\
 Patching & \Circle & \Circle& \CIRCLE & \Circle & \Circle\\
 Periodic Scans & \Circle & \CIRCLE & \CIRCLE & \Circle & \CIRCLE\\
 \hline
\end{tabular}\par
\bigskip
\Circle = No\\
\CIRCLE = Yes\\
\end{center}

\subsection{Security Audit}
Auditing is crucial in any development environment, helping us understand how to keep our cluster running along with industry best practices. 

\subsubsection{Kubeaudit}
Open source tool for auditing a Kubernetes cluster it displays different types of information like a Pod being misconfigured and through this enabling a new attack vector.

\subsubsection{Kubesec}
Open source tool that scans the deployed YAML files, checking for any parameters that may be weakening the security of our cluster.

%\subsubsection{Open Policy Agent}

\subsubsection{Kube Bench}
Open source tool from Aquasecurity, responsible for running an analysis on each node and checking if the node configurations are set up according to security best practices.

\subsubsection{Kube Hunter}
Open source tool from Aquasecurity, responsible for searching for any type of vulnerabilities within our cluster. With this tool we will be able to mitigate information disclosure, configured capabilities, exposed pods, authentication issues, remote code execution, and several others.


\subsection{Secrets Management}
A secure way to store and access the Secrets needed to keep the application running smoothly.
\medskip \\ 

\subsubsection{Vault}
A platform for secrets management and data protection, we can store several types of secrets, Key-Value, ssh keys, TLS Certificates and many more. Once the secrets are stored we can create policies to determine who can read a certain secret and who can create more secrets, having complete control within our organization.
